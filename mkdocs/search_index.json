{
    "docs": [
        {
            "location": "/",
            "text": "Working with molecular structures in pandas DataFrames\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinks\n\n\n\n\nDocumentation: \nhttp://rasbt.github.io/biopandas/\n\n\nSource code repository: \nhttps://github.com/rasbt/biopandas\n\n\nPyPI: \nhttps://pypi.python.org/pypi/biopandas\n\n\n\n\n\n\n\nAbout\n\n\nIf you are a computational biologist, chances are that you cursed one too many times about protein structure files. Yes, I am talking about ye Goode Olde Protein Data Bank format, aka \"PDB files.\" Nothing against PDB, it's a neatly structured format (if deployed correctly); yet, it is a bit cumbersome to work with PDB files in \"modern\" programming languages -- I am pretty sure we all agree on this.\n\n\nAs machine learning and \"data science\" person, I fell in love with \npandas\n DataFrames for handling just about everything that can be loaded into memory.\n\nSo, why don't we take pandas to the structural biology world? Working with molecular structures of biological macromolecules in pandas DataFrames is what BioPandas is all about!\n\n\n\n\n\nExamples\n\n\n\n\n# Initialize a new PandasPDB object\n# and fetch the PDB file from rcsb.org\n>>> from biopandas.pdb import PandasPDB\n>>> ppdb = PandasPDB().fetch_pdb('3eiy')\n>>> ppdb.df['ATOM'].head()\n\n\n\n\n\n\n\n\n\n\n# Load structures from your drive and compute the\n# Root Mean Square Deviation\n>>> from biopandas.pdb import PandasPDB\n>>> pl1 = PandasPDB().read_pdb('./docking_pose_1.pdb')\n>>> pl2 = PandasPDB().read_pdb('./docking_pose_2.pdb')\n>>> r = PandasPDB.rmsd(pl1.df['HETATM'], pl2.df['HETATM'],\n                       s='hydrogen', invert=True)\n>>> print('RMSD: %.4f Angstrom' % r)\nRMSD: 2.6444 Angstrom\n\n\n\n\n\n\n# Producing quick summary plots\n>>> import matplotlib.pyplot as plt\n>>> ppdb.df['ATOM']['b_factor'].plot(kind='hist')\n>>> plt.title('Distribution of B-Factors')\n>>> plt.xlabel('B-factor')\n>>> plt.ylabel('count')\n>>> plt.show()\n\n\n\n\n\n\n\n\n>>> ppdb.df['ATOM']['b_factor'].plot(kind='line')\n>>> plt.title('B-Factors Along the Amino Acid Chain')\n>>> plt.xlabel('Residue Number')\n>>> plt.ylabel('B-factor in $A^2$')\n>>> plt.show()",
            "title": "Home"
        },
        {
            "location": "/tutorials/Working_with_PDB_Structures_in_DataFrames/",
            "text": "Working with PDB Structures in DataFrames\n\n\nLoading PDB Files\n\n\nThere are 2 1/2 ways to load a PDB structure into a \nPandasPDB\n object.\n\n\n1\n\n\nPDB files can be directly fetched from The Protein Data Bank at \nhttp://www.rcsb.org\n via its unique 4-letter after initializing a new \nPandasPDB\n object and calling the \nfetch_pdb\n method:\n\n\nfrom biopandas.pdb import PandasPDB\n\n# Initialize a new PandasPDB object\n# and fetch the PDB file from rcsb.org\nppdb = PandasPDB().fetch_pdb('3eiy')\n\n\n\n\n2 a)\n\n\nAlternatively, we can load PDB files from local directories as regular PDB files using \nread_pdb\n:\n\n\nppdb.read_pdb('./data/3eiy.pdb')\n\n\n\n\n2 b)\n\n\nOr, we can load them from gzip archives like so (note that the file must end with a '.gz' suffix in order to be recognized as a gzip file):\n\n\nppdb.read_pdb('./data/3eiy.pdb.gz')\n\n\n\n\nAfter the file was succesfully loaded, we have access to the following attributes:\n\n\nprint('PDB Code: %s' % ppdb.code)\nprint('PDB Header Line: %s' % ppdb.header)\nprint('\\nRaw PDB file contents:\\n\\n%s\\n...' % ppdb.pdb_text[:1000])\n\n\n\n\n\n    PDB Code: 3eiy\n    PDB Header Line:     HYDROLASE                               17-SEP-08   3EIY\n\n    Raw PDB file contents:\n\n    HEADER    HYDROLASE                               17-SEP-08   3EIY              \n    TITLE     CRYSTAL STRUCTURE OF INORGANIC PYROPHOSPHATASE FROM BURKHOLDERIA      \n    TITLE    2 PSEUDOMALLEI WITH BOUND PYROPHOSPHATE                                \n    COMPND    MOL_ID: 1;                                                            \n    COMPND   2 MOLECULE: INORGANIC PYROPHOSPHATASE;                                 \n    COMPND   3 CHAIN: A;                                                            \n    COMPND   4 EC: 3.6.1.1;                                                         \n    COMPND   5 ENGINEERED: YES                                                      \n    SOURCE    MOL_ID: 1;                                                            \n    SOURCE   2 ORGANISM_SCIENTIFIC: BURKHOLDERIA PSEUDOMALLEI 1710B;                \n    SOURCE   3 ORGANISM_TAXID: 320372;                                              \n    SOURCE   4 GENE: PPA, BURPS1710B_1237;                                          \n    SOURCE   5 EXPRESSION_SYSTEM\n    ...\n\n\n\n\nThe most interesting / useful attribute is the \nPandasPDB.df\n DataFrame dictionary though, which gives us access to the PDB files as pandas DataFrames. Let's print the first 3 lines from the \nATOM\n coordinate section to see how it looks like:\n\n\nppdb.df['ATOM'].head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nrecord_name\n\n      \natom_number\n\n      \nblank_1\n\n      \natom_name\n\n      \n...\n\n      \nsegment_id\n\n      \nelement_symbol\n\n      \ncharge\n\n      \nline_idx\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \nATOM\n\n      \n1\n\n      \n\n      \nN\n\n      \n...\n\n      \n\n      \nN\n\n      \nNaN\n\n      \n609\n\n    \n\n    \n\n      \n1\n\n      \nATOM\n\n      \n2\n\n      \n\n      \nCA\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n610\n\n    \n\n    \n\n      \n2\n\n      \nATOM\n\n      \n3\n\n      \n\n      \nC\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n611\n\n    \n\n  \n\n\n\n\n3 rows \u00d7 21 columns\n\n\n\n\n\nBut more on that in the next section.\n\n\nLooking at PDBs in DataFrames\n\n\nPDB files are parsed according to the \nPDB file format description\n. More specifically, BioPandas reads the columns of the ATOM and HETATM sections as shown in the following excerpt from \nhttp://deposit.rcsb.org/adit/docs/pdb_atom_format.html#ATOM\n.\n\n\n\n\n\n\n\n\nCOLUMNS\n\n\nDATA TYPE\n\n\nCONTENTS\n\n\nbiopandas column name\n\n\n\n\n\n\n\n\n\n\n1 - 6\n\n\nRecord name\n\n\n\"ATOM\"\n\n\nrecord_name\n\n\n\n\n\n\n7 - 11\n\n\nInteger\n\n\nAtom serial number.\n\n\natom_number\n\n\n\n\n\n\n12\n\n\n\n\n\n\nblank_1\n\n\n\n\n\n\n13 - 16\n\n\nAtom\n\n\nAtom name.\n\n\natom_name\n\n\n\n\n\n\n17\n\n\nCharacter\n\n\nAlternate location indicator.\n\n\nalt_loc\n\n\n\n\n\n\n18 - 20\n\n\nResidue name\n\n\nResidue name.\n\n\nresidue_name\n\n\n\n\n\n\n21\n\n\n\n\n\n\nblank_2\n\n\n\n\n\n\n22\n\n\nCharacter\n\n\nChain identifier.\n\n\nchain_id\n\n\n\n\n\n\n23 - 26\n\n\nInteger\n\n\nResidue sequence number.\n\n\nresidue_number\n\n\n\n\n\n\n27\n\n\nAChar\n\n\nCode for insertion of residues.\n\n\ninsertion\n\n\n\n\n\n\n28 - 30\n\n\n\n\n\n\nblank_3\n\n\n\n\n\n\n31 - 38\n\n\nReal(8.3)\n\n\nOrthogonal coordinates for X in Angstroms.\n\n\nx_coord\n\n\n\n\n\n\n39 - 46\n\n\nReal(8.3)\n\n\nOrthogonal coordinates for Y in Angstroms.\n\n\ny_coord\n\n\n\n\n\n\n47 - 54\n\n\nReal(8.3)\n\n\nOrthogonal coordinates for Z in Angstroms.\n\n\nz_coord\n\n\n\n\n\n\n55 - 60\n\n\nReal(6.2)\n\n\nOccupancy.\n\n\noccupancy\n\n\n\n\n\n\n61 - 66\n\n\nReal(6.2)\n\n\nTemperature factor (Default = 0.0).\n\n\nbfactor\n\n\n\n\n\n\n67-72\n\n\n\n\n\n\nblank_4\n\n\n\n\n\n\n73 - 76\n\n\nLString(4)\n\n\nSegment identifier, left-justified.\n\n\nsegment_id\n\n\n\n\n\n\n77 - 78\n\n\nLString(2)\n\n\nElement symbol, right-justified.\n\n\nelement_symbol\n\n\n\n\n\n\n79 - 80\n\n\nLString(2)\n\n\nCharge on the atom.\n\n\ncharge\n\n\n\n\n\n\n\n\nBelow is an example of how this would look like in an actual PDB file:\n\n\nExample:\n         1         2         3         4         5         6         7         8\n12345678901234567890123456789012345678901234567890123456789012345678901234567890\nATOM    145  N   VAL A  25      32.433  16.336  57.540  1.00 11.92      A1   N\nATOM    146  CA  VAL A  25      31.132  16.439  58.160  1.00 11.85      A1   C\nATOM    147  C   VAL A  25      30.447  15.105  58.363  1.00 12.34      A1   C\nATOM    148  O   VAL A  25      29.520  15.059  59.174  1.00 15.65      A1   O\nATOM    149  CB AVAL A  25      30.385  17.437  57.230  0.28 13.88      A1   C\nATOM    150  CB BVAL A  25      30.166  17.399  57.373  0.72 15.41      A1   C\nATOM    151  CG1AVAL A  25      28.870  17.401  57.336  0.28 12.64      A1   C\nATOM    152  CG1BVAL A  25      30.805  18.788  57.449  0.72 15.11      A1   C\nATOM    153  CG2AVAL A  25      30.835  18.826  57.661  0.28 13.58      A1   C\nATOM    154  CG2BVAL A  25      29.909  16.996  55.922  0.72 13.25      A1   C\n\n\n\nAfter loading a PDB file from rcsb.org or our local drive, the \nPandasPDB.df\n attribute should contain the following 4 DataFrame objects:\n\n\nfrom biopandas.pdb import PandasPDB\nppdb = PandasPDB()\nppdb.read_pdb('./data/3eiy.pdb')\nppdb.df.keys()\n\n\n\n\ndict_keys(['ANISOU', 'ATOM', 'OTHERS', 'HETATM'])\n\n\n\n\n\n'ATOM': contains the entries from the ATOM coordinate section\n\n\n'ATOM':  ... entries from the \"HETATM\" coordinate section    \n\n\n'ANISOU': ... entries from the \"ANISOU\" coordinate section\n\n\n'OTHERS': Everything else that is \nnot\n a 'ATOM', 'HETATM', or 'ANISOU' entry\n\n\n\n\n\n\nThe columns of the 'HETATM' DataFrame are indentical to the 'ATOM' DataFrame that we've seen earlier:\n\n\nppdb.df['HETATM'].head(2)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nrecord_name\n\n      \natom_number\n\n      \nblank_1\n\n      \natom_name\n\n      \n...\n\n      \nsegment_id\n\n      \nelement_symbol\n\n      \ncharge\n\n      \nline_idx\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \nHETATM\n\n      \n1332\n\n      \n\n      \nK\n\n      \n...\n\n      \n\n      \nK\n\n      \nNaN\n\n      \n1940\n\n    \n\n    \n\n      \n1\n\n      \nHETATM\n\n      \n1333\n\n      \n\n      \nNA\n\n      \n...\n\n      \n\n      \nNA\n\n      \nNaN\n\n      \n1941\n\n    \n\n  \n\n\n\n\n2 rows \u00d7 21 columns\n\n\n\n\n\n\n\nNote that \"ANISOU\" entries are handled a bit differently as specified at \nhttp://deposit.rcsb.org/adit/docs/pdb_atom_format.html#ATOM\n.\n\n\nppdb.df['ANISOU'].head(2)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nrecord_name\n\n      \natom_number\n\n      \nblank_1\n\n      \natom_name\n\n      \n...\n\n      \nblank_4\n\n      \nelement_symbol\n\n      \ncharge\n\n      \nline_idx\n\n    \n\n  \n\n  \n\n  \n\n\n\n\n0 rows \u00d7 21 columns\n\n\n\n\n\nNot every PDB file contains ANISOU entries (similarly, some PDB files may only contain HETATM or ATOM entries). If records are basent, the DataFrame will be empty as show above.\n\n\nppdb.df['ANISOU'].empty\n\n\n\n\nTrue\n\n\n\nSince the DataFrames are fairly wide, let's us take a look at the columns by accessing the DataFrame's \ncolumn\n attribute:\n\n\nppdb.df['ANISOU'].columns\n\n\n\n\nIndex(['record_name', 'atom_number', 'blank_1', 'atom_name', 'alt_loc', 'residue_name', 'blank_2', 'chain_id', 'residue_number', 'insertion', 'blank_3', 'U(1,1)', 'U(2,2)', 'U(3,3)', 'U(1,2)', 'U(1,3)', 'U(2,3)', 'blank_4', 'element_symbol', 'charge', 'line_idx'], dtype='object')\n\n\n\nANISOU records are very similar to ATOM/HETATM records. In fact, the columns 7 - 27 and 73 - 80 are identical to their corresponding ATOM/HETATM records, which means that the 'ANISOU' DataFrame doesn't have the following entries:\n\n\nset(ppdb.df['ATOM'].columns).difference(set(ppdb.df['ANISOU'].columns))\n\n\n\n\n{'b_factor', 'occupancy', 'segment_id', 'x_coord', 'y_coord', 'z_coord'}\n\n\n\nInstead, the \"ANISOU\" DataFrame contains the anisotropic temperature factors \"U(-,-)\" -- note that these are scaled by a factor of \n$10^4$\n (\n$\\text{Angstroms}^2$\n) by convention.\n\n\nset(ppdb.df['ANISOU'].columns).difference(set(ppdb.df['ATOM'].columns))\n\n\n\n\n{'U(1,1)', 'U(1,2)', 'U(1,3)', 'U(2,2)', 'U(2,3)', 'U(3,3)'}\n\n\n\n\n\n\n\nAh, another interesting thing to mention is that the columns already come with the types you'd expect (where \nobject\n essentially \"means\" \nstr\n here):\n\n\nppdb.df['ATOM'].dtypes\n\n\n\n\nrecord_name        object\natom_number         int64\nblank_1            object\natom_name          object\nalt_loc            object\nresidue_name       object\nblank_2            object\nchain_id           object\nresidue_number      int64\ninsertion          object\nblank_3            object\nx_coord           float64\ny_coord           float64\nz_coord           float64\noccupancy         float64\nb_factor          float64\nblank_4            object\nsegment_id         object\nelement_symbol     object\ncharge            float64\nline_idx            int64\ndtype: object\n\n\n\n\n\nTypically, all good things come in threes, however, there is a 4th DataFrame, an'OTHER' DataFrame, which contains everything that wasn't parsed as 'ATOM', 'HETATM', or 'ANISOU' coordinate section:\n\n\nppdb.df['OTHERS'].head(5)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nrecord_name\n\n      \nentry\n\n      \nline_idx\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \nHEADER\n\n      \nHYDROLASE                               17...\n\n      \n0\n\n    \n\n    \n\n      \n1\n\n      \nTITLE\n\n      \nCRYSTAL STRUCTURE OF INORGANIC PYROPHOSPHA...\n\n      \n1\n\n    \n\n    \n\n      \n2\n\n      \nTITLE\n\n      \n2 PSEUDOMALLEI WITH BOUND PYROPHOSPHATE\n\n      \n2\n\n    \n\n    \n\n      \n3\n\n      \nCOMPND\n\n      \nMOL_ID: 1;\n\n      \n3\n\n    \n\n    \n\n      \n4\n\n      \nCOMPND\n\n      \n2 MOLECULE: INORGANIC PYROPHOSPHATASE;\n\n      \n4\n\n    \n\n  \n\n\n\n\n\n\n\nAlthough these 'OTHER' entries are typically less useful for structure-related computations, you may still want to take a look at them to get a short summary of the PDB structure and learn about it's potential quirks and gotchas (typically listed in the REMARKs section). Lastly, the \"OTHERS\" DataFrame comes in handy if we want to reconstruct the structure as PDB file as we will see later (note the \nline_idx\n columns in all of the DataFrames).\n\n\nWorking with PDB DataFrames\n\n\nIn the previous sections, we've seen how to load PDB structures into DataFrames, and how to access them. Now, let's talk about manipulating PDB files in DataFrames.\n\n\nfrom biopandas.pdb import PandasPDB\nppdb = PandasPDB()\nppdb.read_pdb('./data/3eiy.pdb.gz')\nppdb.df['ATOM'].head()\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nrecord_name\n\n      \natom_number\n\n      \nblank_1\n\n      \natom_name\n\n      \n...\n\n      \nsegment_id\n\n      \nelement_symbol\n\n      \ncharge\n\n      \nline_idx\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \nATOM\n\n      \n1\n\n      \n\n      \nN\n\n      \n...\n\n      \n\n      \nN\n\n      \nNaN\n\n      \n609\n\n    \n\n    \n\n      \n1\n\n      \nATOM\n\n      \n2\n\n      \n\n      \nCA\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n610\n\n    \n\n    \n\n      \n2\n\n      \nATOM\n\n      \n3\n\n      \n\n      \nC\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n611\n\n    \n\n    \n\n      \n3\n\n      \nATOM\n\n      \n4\n\n      \n\n      \nO\n\n      \n...\n\n      \n\n      \nO\n\n      \nNaN\n\n      \n612\n\n    \n\n    \n\n      \n4\n\n      \nATOM\n\n      \n5\n\n      \n\n      \nCB\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n613\n\n    \n\n  \n\n\n\n\n5 rows \u00d7 21 columns\n\n\n\n\n\nOkay, there's actually not \nthat\n much to say ... \n\nOnce we have our PDB file in the DataFrame format, we have the whole convenience of \npandas\n right there at our fingertips.\n\n\nFor example, let's get all Proline residues:\n\n\nppdb.df['ATOM'][ppdb.df['ATOM']['residue_name'] == 'PRO'].head()\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nrecord_name\n\n      \natom_number\n\n      \nblank_1\n\n      \natom_name\n\n      \n...\n\n      \nsegment_id\n\n      \nelement_symbol\n\n      \ncharge\n\n      \nline_idx\n\n    \n\n  \n\n  \n\n    \n\n      \n38\n\n      \nATOM\n\n      \n39\n\n      \n\n      \nN\n\n      \n...\n\n      \n\n      \nN\n\n      \nNaN\n\n      \n647\n\n    \n\n    \n\n      \n39\n\n      \nATOM\n\n      \n40\n\n      \n\n      \nCA\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n648\n\n    \n\n    \n\n      \n40\n\n      \nATOM\n\n      \n41\n\n      \n\n      \nC\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n649\n\n    \n\n    \n\n      \n41\n\n      \nATOM\n\n      \n42\n\n      \n\n      \nO\n\n      \n...\n\n      \n\n      \nO\n\n      \nNaN\n\n      \n650\n\n    \n\n    \n\n      \n42\n\n      \nATOM\n\n      \n43\n\n      \n\n      \nCB\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n651\n\n    \n\n  \n\n\n\n\n5 rows \u00d7 21 columns\n\n\n\n\n\nOr main chain atoms:\n\n\nppdb.df['ATOM'][ppdb.df['ATOM']['atom_name'] == 'C'].head()\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nrecord_name\n\n      \natom_number\n\n      \nblank_1\n\n      \natom_name\n\n      \n...\n\n      \nsegment_id\n\n      \nelement_symbol\n\n      \ncharge\n\n      \nline_idx\n\n    \n\n  \n\n  \n\n    \n\n      \n2\n\n      \nATOM\n\n      \n3\n\n      \n\n      \nC\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n611\n\n    \n\n    \n\n      \n8\n\n      \nATOM\n\n      \n9\n\n      \n\n      \nC\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n617\n\n    \n\n    \n\n      \n19\n\n      \nATOM\n\n      \n20\n\n      \n\n      \nC\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n628\n\n    \n\n    \n\n      \n25\n\n      \nATOM\n\n      \n26\n\n      \n\n      \nC\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n634\n\n    \n\n    \n\n      \n33\n\n      \nATOM\n\n      \n34\n\n      \n\n      \nC\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n642\n\n    \n\n  \n\n\n\n\n5 rows \u00d7 21 columns\n\n\n\n\n\nIt's also easy to strip our coordinate section from hydrogen atoms if there are any ...\n\n\nppdb.df['ATOM'][ppdb.df['ATOM']['element_symbol'] != 'H'].head()\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nrecord_name\n\n      \natom_number\n\n      \nblank_1\n\n      \natom_name\n\n      \n...\n\n      \nsegment_id\n\n      \nelement_symbol\n\n      \ncharge\n\n      \nline_idx\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \nATOM\n\n      \n1\n\n      \n\n      \nN\n\n      \n...\n\n      \n\n      \nN\n\n      \nNaN\n\n      \n609\n\n    \n\n    \n\n      \n1\n\n      \nATOM\n\n      \n2\n\n      \n\n      \nCA\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n610\n\n    \n\n    \n\n      \n2\n\n      \nATOM\n\n      \n3\n\n      \n\n      \nC\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n611\n\n    \n\n    \n\n      \n3\n\n      \nATOM\n\n      \n4\n\n      \n\n      \nO\n\n      \n...\n\n      \n\n      \nO\n\n      \nNaN\n\n      \n612\n\n    \n\n    \n\n      \n4\n\n      \nATOM\n\n      \n5\n\n      \n\n      \nCB\n\n      \n...\n\n      \n\n      \nC\n\n      \nNaN\n\n      \n613\n\n    \n\n  \n\n\n\n\n5 rows \u00d7 21 columns\n\n\n\n\n\nOr, let's compute the average temperature factor of our protein main chain:\n\n\nmainchain = ppdb.df['ATOM'][(ppdb.df['ATOM']['atom_name'] == 'C') |\n                            (ppdb.df['ATOM']['atom_name'] == 'O') |\n                            (ppdb.df['ATOM']['atom_name'] == 'N') |\n                            (ppdb.df['ATOM']['atom_name'] == 'CA')]\n\nbfact_mc_avg = mainchain['b_factor'].mean()\nprint('Average B-Factor [Main Chain]: %.2f' % bfact_mc_avg)\n\n\n\n\nAverage B-Factor [Main Chain]: 28.83\n\n\n\nPlotting\n\n\nSince we are using pandas under the hood, which in turns uses matplotlib under the hood, we can produce quick summary plots of our PDB structures relatively conveniently:\n\n\nfrom biopandas.pdb import PandasPDB\nppdb = PandasPDB().read_pdb('./data/3eiy.pdb.gz')\n\n\n\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nstyle.use('ggplot')\n\n\n\n\nppdb.df['ATOM']['b_factor'].plot(kind='hist')\nplt.title('Distribution of B-Factors')\nplt.xlabel('B-factor')\nplt.ylabel('count')\nplt.show()\n\n\n\n\n\n\nppdb.df['ATOM']['b_factor'].plot(kind='line')\nplt.title('B-Factors Along the Amino Acid Chain')\nplt.xlabel('Residue Number')\nplt.ylabel('B-factor in $A^2$')\nplt.show()\n\n\n\n\n\n\nppdb.df['ATOM']['element_symbol'].value_counts().plot(kind='bar')\nplt.title('Distribution of Atom Types')\nplt.xlabel('elements')\nplt.ylabel('count')\nplt.show()\n\n\n\n\n\n\nComputing the Root Mean Square Deviation\n\n\nBioPandas also comes with certain convenience functions, for example, ...\n\n\nThe [Root-mean-square deviation] (RMSD) is simply a measure of the average distance between atoms of 2 protein or ligand structures. This calculation of the Cartesian error follows the equation:\n\n\n$$RMSD(a, b) = \\sqrt{\\frac{1}{n} \\sum^{n}_{i=1} \\big((a_{ix})^2 + (a_{iy})^2 + (a_{iz})^2 \\big)} \\\\\n= \\sqrt{\\frac{1}{n} \\sum^{n}_{i=1} || a_i + b_i||_2^2}$$\n\n\nSo, assuming that the we have the following 2 conformation of a ligand molecule\n\n\n\n\nwe can compute the RMSD as follows:\n\n\nfrom biopandas.pdb import PandasPDB\n\nl_1 = PandasPDB().read_pdb('./data/lig_conf_1.pdb')\nl_2 = PandasPDB().read_pdb('./data/lig_conf_2.pdb')\nr = PandasPDB.rmsd(l_1.df['HETATM'], l_2.df['HETATM'], s='hydrogen', invert=True)\nprint('RMSD: %.4f Angstrom' % r)\n\n\n\n\nRMSD: 2.6444 Angstrom\n\n\n\nNote that the \ns\n parameter in \nPandasPDB.rmsd\n specifies the search string \"consider all hydrogen atoms\" and via the \ninvert=True\n option, we say \"Compute the RMSD for everything BUT the hydrogen atoms\" or \"Compute the RSMD based on the heavy atoms only\".\n\n\nSimilarly, we can compute the RMSD between 2 related protein structures:\n\n\n\n\nThe hydrogen-free RMSD:\n\n\np_1 = PandasPDB().read_pdb('./data/1t48_995.pdb')\np_2 = PandasPDB().read_pdb('./data/1t49_995.pdb')\nr = PandasPDB.rmsd(p_1.df['ATOM'], p_2.df['ATOM'], s='hydrogen', invert=True)\nprint('RMSD: %.4f Angstrom' % r)\n\n\n\n\nRMSD: 0.7377 Angstrom\n\n\n\nOr the RMSD between the main chains only:\n\n\np_1 = PandasPDB().read_pdb('./data/1t48_995.pdb')\np_2 = PandasPDB().read_pdb('./data/1t49_995.pdb')\nr = PandasPDB.rmsd(p_1.df['ATOM'], p_2.df['ATOM'], s='main chain', invert=False)\nprint('RMSD: %.4f Angstrom' % r)\n\n\n\n\nRMSD: 0.4781 Angstrom\n\n\n\n\n\n[more to come]\n\n\nWrapping it up - Saving PDB structures\n\n\nFinally, let's talk about how to get the PDB structures out of the DataFrame format back into the beloved .pdb format.\n\n\nLet's say we loaded a PDB structure, removed it from it's hydrogens:\n\n\nfrom biopandas.pdb import PandasPDB\nppdb = PandasPDB().read_pdb('./data/3eiy.pdb.gz')\nppdb.df['ATOM'] = ppdb.df['ATOM'][ppdb.df['ATOM']['element_symbol'] != 'H']\n\n\n\n\nWe can save the file using the \nPandasPDB.to_pdb\n method:\n\n\nppdb.to_pdb(path='./data/3eiy_stripped.pdb',\n            records=None,\n            gz=False,\n            append_newline=True)\n\n\n\n\nBy default, all records (that is, 'ATOM', 'HETATM', 'OTHERS', 'ANISOU') are written if we set \nrecords=None\n. Alternatively, let's say we want to get rid of the 'ANISOU' entries and produce a compressed gzip archive of our PDB structure:\n\n\nppdb.to_pdb(path='./data/3eiy_stripped.pdb.gz',\n            records=['ATOM', 'HETATM', 'OTHERS'],\n            gz=True,\n            append_newline=True)",
            "title": "Working with PDB Structures in DataFrames"
        },
        {
            "location": "/tutorials/Working_with_PDB_Structures_in_DataFrames/#working-with-pdb-structures-in-dataframes",
            "text": "",
            "title": "Working with PDB Structures in DataFrames"
        },
        {
            "location": "/tutorials/Working_with_PDB_Structures_in_DataFrames/#loading-pdb-files",
            "text": "There are 2 1/2 ways to load a PDB structure into a  PandasPDB  object.  1  PDB files can be directly fetched from The Protein Data Bank at  http://www.rcsb.org  via its unique 4-letter after initializing a new  PandasPDB  object and calling the  fetch_pdb  method:  from biopandas.pdb import PandasPDB\n\n# Initialize a new PandasPDB object\n# and fetch the PDB file from rcsb.org\nppdb = PandasPDB().fetch_pdb('3eiy')  2 a)  Alternatively, we can load PDB files from local directories as regular PDB files using  read_pdb :  ppdb.read_pdb('./data/3eiy.pdb')  2 b)  Or, we can load them from gzip archives like so (note that the file must end with a '.gz' suffix in order to be recognized as a gzip file):  ppdb.read_pdb('./data/3eiy.pdb.gz')  After the file was succesfully loaded, we have access to the following attributes:  print('PDB Code: %s' % ppdb.code)\nprint('PDB Header Line: %s' % ppdb.header)\nprint('\\nRaw PDB file contents:\\n\\n%s\\n...' % ppdb.pdb_text[:1000])  \n    PDB Code: 3eiy\n    PDB Header Line:     HYDROLASE                               17-SEP-08   3EIY\n\n    Raw PDB file contents:\n\n    HEADER    HYDROLASE                               17-SEP-08   3EIY              \n    TITLE     CRYSTAL STRUCTURE OF INORGANIC PYROPHOSPHATASE FROM BURKHOLDERIA      \n    TITLE    2 PSEUDOMALLEI WITH BOUND PYROPHOSPHATE                                \n    COMPND    MOL_ID: 1;                                                            \n    COMPND   2 MOLECULE: INORGANIC PYROPHOSPHATASE;                                 \n    COMPND   3 CHAIN: A;                                                            \n    COMPND   4 EC: 3.6.1.1;                                                         \n    COMPND   5 ENGINEERED: YES                                                      \n    SOURCE    MOL_ID: 1;                                                            \n    SOURCE   2 ORGANISM_SCIENTIFIC: BURKHOLDERIA PSEUDOMALLEI 1710B;                \n    SOURCE   3 ORGANISM_TAXID: 320372;                                              \n    SOURCE   4 GENE: PPA, BURPS1710B_1237;                                          \n    SOURCE   5 EXPRESSION_SYSTEM\n    ...  The most interesting / useful attribute is the  PandasPDB.df  DataFrame dictionary though, which gives us access to the PDB files as pandas DataFrames. Let's print the first 3 lines from the  ATOM  coordinate section to see how it looks like:  ppdb.df['ATOM'].head(3)   \n   \n     \n       \n       record_name \n       atom_number \n       blank_1 \n       atom_name \n       ... \n       segment_id \n       element_symbol \n       charge \n       line_idx \n     \n   \n   \n     \n       0 \n       ATOM \n       1 \n       \n       N \n       ... \n       \n       N \n       NaN \n       609 \n     \n     \n       1 \n       ATOM \n       2 \n       \n       CA \n       ... \n       \n       C \n       NaN \n       610 \n     \n     \n       2 \n       ATOM \n       3 \n       \n       C \n       ... \n       \n       C \n       NaN \n       611 \n     \n     3 rows \u00d7 21 columns   But more on that in the next section.",
            "title": "Loading PDB Files"
        },
        {
            "location": "/tutorials/Working_with_PDB_Structures_in_DataFrames/#looking-at-pdbs-in-dataframes",
            "text": "PDB files are parsed according to the  PDB file format description . More specifically, BioPandas reads the columns of the ATOM and HETATM sections as shown in the following excerpt from  http://deposit.rcsb.org/adit/docs/pdb_atom_format.html#ATOM .     COLUMNS  DATA TYPE  CONTENTS  biopandas column name      1 - 6  Record name  \"ATOM\"  record_name    7 - 11  Integer  Atom serial number.  atom_number    12    blank_1    13 - 16  Atom  Atom name.  atom_name    17  Character  Alternate location indicator.  alt_loc    18 - 20  Residue name  Residue name.  residue_name    21    blank_2    22  Character  Chain identifier.  chain_id    23 - 26  Integer  Residue sequence number.  residue_number    27  AChar  Code for insertion of residues.  insertion    28 - 30    blank_3    31 - 38  Real(8.3)  Orthogonal coordinates for X in Angstroms.  x_coord    39 - 46  Real(8.3)  Orthogonal coordinates for Y in Angstroms.  y_coord    47 - 54  Real(8.3)  Orthogonal coordinates for Z in Angstroms.  z_coord    55 - 60  Real(6.2)  Occupancy.  occupancy    61 - 66  Real(6.2)  Temperature factor (Default = 0.0).  bfactor    67-72    blank_4    73 - 76  LString(4)  Segment identifier, left-justified.  segment_id    77 - 78  LString(2)  Element symbol, right-justified.  element_symbol    79 - 80  LString(2)  Charge on the atom.  charge     Below is an example of how this would look like in an actual PDB file:  Example:\n         1         2         3         4         5         6         7         8\n12345678901234567890123456789012345678901234567890123456789012345678901234567890\nATOM    145  N   VAL A  25      32.433  16.336  57.540  1.00 11.92      A1   N\nATOM    146  CA  VAL A  25      31.132  16.439  58.160  1.00 11.85      A1   C\nATOM    147  C   VAL A  25      30.447  15.105  58.363  1.00 12.34      A1   C\nATOM    148  O   VAL A  25      29.520  15.059  59.174  1.00 15.65      A1   O\nATOM    149  CB AVAL A  25      30.385  17.437  57.230  0.28 13.88      A1   C\nATOM    150  CB BVAL A  25      30.166  17.399  57.373  0.72 15.41      A1   C\nATOM    151  CG1AVAL A  25      28.870  17.401  57.336  0.28 12.64      A1   C\nATOM    152  CG1BVAL A  25      30.805  18.788  57.449  0.72 15.11      A1   C\nATOM    153  CG2AVAL A  25      30.835  18.826  57.661  0.28 13.58      A1   C\nATOM    154  CG2BVAL A  25      29.909  16.996  55.922  0.72 13.25      A1   C  After loading a PDB file from rcsb.org or our local drive, the  PandasPDB.df  attribute should contain the following 4 DataFrame objects:  from biopandas.pdb import PandasPDB\nppdb = PandasPDB()\nppdb.read_pdb('./data/3eiy.pdb')\nppdb.df.keys()  dict_keys(['ANISOU', 'ATOM', 'OTHERS', 'HETATM'])   'ATOM': contains the entries from the ATOM coordinate section  'ATOM':  ... entries from the \"HETATM\" coordinate section      'ANISOU': ... entries from the \"ANISOU\" coordinate section  'OTHERS': Everything else that is  not  a 'ATOM', 'HETATM', or 'ANISOU' entry    The columns of the 'HETATM' DataFrame are indentical to the 'ATOM' DataFrame that we've seen earlier:  ppdb.df['HETATM'].head(2)   \n   \n     \n       \n       record_name \n       atom_number \n       blank_1 \n       atom_name \n       ... \n       segment_id \n       element_symbol \n       charge \n       line_idx \n     \n   \n   \n     \n       0 \n       HETATM \n       1332 \n       \n       K \n       ... \n       \n       K \n       NaN \n       1940 \n     \n     \n       1 \n       HETATM \n       1333 \n       \n       NA \n       ... \n       \n       NA \n       NaN \n       1941 \n     \n     2 rows \u00d7 21 columns    Note that \"ANISOU\" entries are handled a bit differently as specified at  http://deposit.rcsb.org/adit/docs/pdb_atom_format.html#ATOM .  ppdb.df['ANISOU'].head(2)   \n   \n     \n       \n       record_name \n       atom_number \n       blank_1 \n       atom_name \n       ... \n       blank_4 \n       element_symbol \n       charge \n       line_idx \n     \n   \n   \n     0 rows \u00d7 21 columns   Not every PDB file contains ANISOU entries (similarly, some PDB files may only contain HETATM or ATOM entries). If records are basent, the DataFrame will be empty as show above.  ppdb.df['ANISOU'].empty  True  Since the DataFrames are fairly wide, let's us take a look at the columns by accessing the DataFrame's  column  attribute:  ppdb.df['ANISOU'].columns  Index(['record_name', 'atom_number', 'blank_1', 'atom_name', 'alt_loc', 'residue_name', 'blank_2', 'chain_id', 'residue_number', 'insertion', 'blank_3', 'U(1,1)', 'U(2,2)', 'U(3,3)', 'U(1,2)', 'U(1,3)', 'U(2,3)', 'blank_4', 'element_symbol', 'charge', 'line_idx'], dtype='object')  ANISOU records are very similar to ATOM/HETATM records. In fact, the columns 7 - 27 and 73 - 80 are identical to their corresponding ATOM/HETATM records, which means that the 'ANISOU' DataFrame doesn't have the following entries:  set(ppdb.df['ATOM'].columns).difference(set(ppdb.df['ANISOU'].columns))  {'b_factor', 'occupancy', 'segment_id', 'x_coord', 'y_coord', 'z_coord'}  Instead, the \"ANISOU\" DataFrame contains the anisotropic temperature factors \"U(-,-)\" -- note that these are scaled by a factor of  $10^4$  ( $\\text{Angstroms}^2$ ) by convention.  set(ppdb.df['ANISOU'].columns).difference(set(ppdb.df['ATOM'].columns))  {'U(1,1)', 'U(1,2)', 'U(1,3)', 'U(2,2)', 'U(2,3)', 'U(3,3)'}    Ah, another interesting thing to mention is that the columns already come with the types you'd expect (where  object  essentially \"means\"  str  here):  ppdb.df['ATOM'].dtypes  record_name        object\natom_number         int64\nblank_1            object\natom_name          object\nalt_loc            object\nresidue_name       object\nblank_2            object\nchain_id           object\nresidue_number      int64\ninsertion          object\nblank_3            object\nx_coord           float64\ny_coord           float64\nz_coord           float64\noccupancy         float64\nb_factor          float64\nblank_4            object\nsegment_id         object\nelement_symbol     object\ncharge            float64\nline_idx            int64\ndtype: object   Typically, all good things come in threes, however, there is a 4th DataFrame, an'OTHER' DataFrame, which contains everything that wasn't parsed as 'ATOM', 'HETATM', or 'ANISOU' coordinate section:  ppdb.df['OTHERS'].head(5)   \n   \n     \n       \n       record_name \n       entry \n       line_idx \n     \n   \n   \n     \n       0 \n       HEADER \n       HYDROLASE                               17... \n       0 \n     \n     \n       1 \n       TITLE \n       CRYSTAL STRUCTURE OF INORGANIC PYROPHOSPHA... \n       1 \n     \n     \n       2 \n       TITLE \n       2 PSEUDOMALLEI WITH BOUND PYROPHOSPHATE \n       2 \n     \n     \n       3 \n       COMPND \n       MOL_ID: 1; \n       3 \n     \n     \n       4 \n       COMPND \n       2 MOLECULE: INORGANIC PYROPHOSPHATASE; \n       4 \n     \n      Although these 'OTHER' entries are typically less useful for structure-related computations, you may still want to take a look at them to get a short summary of the PDB structure and learn about it's potential quirks and gotchas (typically listed in the REMARKs section). Lastly, the \"OTHERS\" DataFrame comes in handy if we want to reconstruct the structure as PDB file as we will see later (note the  line_idx  columns in all of the DataFrames).",
            "title": "Looking at PDBs in DataFrames"
        },
        {
            "location": "/tutorials/Working_with_PDB_Structures_in_DataFrames/#working-with-pdb-dataframes",
            "text": "In the previous sections, we've seen how to load PDB structures into DataFrames, and how to access them. Now, let's talk about manipulating PDB files in DataFrames.  from biopandas.pdb import PandasPDB\nppdb = PandasPDB()\nppdb.read_pdb('./data/3eiy.pdb.gz')\nppdb.df['ATOM'].head()   \n   \n     \n       \n       record_name \n       atom_number \n       blank_1 \n       atom_name \n       ... \n       segment_id \n       element_symbol \n       charge \n       line_idx \n     \n   \n   \n     \n       0 \n       ATOM \n       1 \n       \n       N \n       ... \n       \n       N \n       NaN \n       609 \n     \n     \n       1 \n       ATOM \n       2 \n       \n       CA \n       ... \n       \n       C \n       NaN \n       610 \n     \n     \n       2 \n       ATOM \n       3 \n       \n       C \n       ... \n       \n       C \n       NaN \n       611 \n     \n     \n       3 \n       ATOM \n       4 \n       \n       O \n       ... \n       \n       O \n       NaN \n       612 \n     \n     \n       4 \n       ATOM \n       5 \n       \n       CB \n       ... \n       \n       C \n       NaN \n       613 \n     \n     5 rows \u00d7 21 columns   Okay, there's actually not  that  much to say ...  \nOnce we have our PDB file in the DataFrame format, we have the whole convenience of  pandas  right there at our fingertips.  For example, let's get all Proline residues:  ppdb.df['ATOM'][ppdb.df['ATOM']['residue_name'] == 'PRO'].head()   \n   \n     \n       \n       record_name \n       atom_number \n       blank_1 \n       atom_name \n       ... \n       segment_id \n       element_symbol \n       charge \n       line_idx \n     \n   \n   \n     \n       38 \n       ATOM \n       39 \n       \n       N \n       ... \n       \n       N \n       NaN \n       647 \n     \n     \n       39 \n       ATOM \n       40 \n       \n       CA \n       ... \n       \n       C \n       NaN \n       648 \n     \n     \n       40 \n       ATOM \n       41 \n       \n       C \n       ... \n       \n       C \n       NaN \n       649 \n     \n     \n       41 \n       ATOM \n       42 \n       \n       O \n       ... \n       \n       O \n       NaN \n       650 \n     \n     \n       42 \n       ATOM \n       43 \n       \n       CB \n       ... \n       \n       C \n       NaN \n       651 \n     \n     5 rows \u00d7 21 columns   Or main chain atoms:  ppdb.df['ATOM'][ppdb.df['ATOM']['atom_name'] == 'C'].head()   \n   \n     \n       \n       record_name \n       atom_number \n       blank_1 \n       atom_name \n       ... \n       segment_id \n       element_symbol \n       charge \n       line_idx \n     \n   \n   \n     \n       2 \n       ATOM \n       3 \n       \n       C \n       ... \n       \n       C \n       NaN \n       611 \n     \n     \n       8 \n       ATOM \n       9 \n       \n       C \n       ... \n       \n       C \n       NaN \n       617 \n     \n     \n       19 \n       ATOM \n       20 \n       \n       C \n       ... \n       \n       C \n       NaN \n       628 \n     \n     \n       25 \n       ATOM \n       26 \n       \n       C \n       ... \n       \n       C \n       NaN \n       634 \n     \n     \n       33 \n       ATOM \n       34 \n       \n       C \n       ... \n       \n       C \n       NaN \n       642 \n     \n     5 rows \u00d7 21 columns   It's also easy to strip our coordinate section from hydrogen atoms if there are any ...  ppdb.df['ATOM'][ppdb.df['ATOM']['element_symbol'] != 'H'].head()   \n   \n     \n       \n       record_name \n       atom_number \n       blank_1 \n       atom_name \n       ... \n       segment_id \n       element_symbol \n       charge \n       line_idx \n     \n   \n   \n     \n       0 \n       ATOM \n       1 \n       \n       N \n       ... \n       \n       N \n       NaN \n       609 \n     \n     \n       1 \n       ATOM \n       2 \n       \n       CA \n       ... \n       \n       C \n       NaN \n       610 \n     \n     \n       2 \n       ATOM \n       3 \n       \n       C \n       ... \n       \n       C \n       NaN \n       611 \n     \n     \n       3 \n       ATOM \n       4 \n       \n       O \n       ... \n       \n       O \n       NaN \n       612 \n     \n     \n       4 \n       ATOM \n       5 \n       \n       CB \n       ... \n       \n       C \n       NaN \n       613 \n     \n     5 rows \u00d7 21 columns   Or, let's compute the average temperature factor of our protein main chain:  mainchain = ppdb.df['ATOM'][(ppdb.df['ATOM']['atom_name'] == 'C') |\n                            (ppdb.df['ATOM']['atom_name'] == 'O') |\n                            (ppdb.df['ATOM']['atom_name'] == 'N') |\n                            (ppdb.df['ATOM']['atom_name'] == 'CA')]\n\nbfact_mc_avg = mainchain['b_factor'].mean()\nprint('Average B-Factor [Main Chain]: %.2f' % bfact_mc_avg)  Average B-Factor [Main Chain]: 28.83",
            "title": "Working with PDB DataFrames"
        },
        {
            "location": "/tutorials/Working_with_PDB_Structures_in_DataFrames/#plotting",
            "text": "Since we are using pandas under the hood, which in turns uses matplotlib under the hood, we can produce quick summary plots of our PDB structures relatively conveniently:  from biopandas.pdb import PandasPDB\nppdb = PandasPDB().read_pdb('./data/3eiy.pdb.gz')  %matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nstyle.use('ggplot')  ppdb.df['ATOM']['b_factor'].plot(kind='hist')\nplt.title('Distribution of B-Factors')\nplt.xlabel('B-factor')\nplt.ylabel('count')\nplt.show()   ppdb.df['ATOM']['b_factor'].plot(kind='line')\nplt.title('B-Factors Along the Amino Acid Chain')\nplt.xlabel('Residue Number')\nplt.ylabel('B-factor in $A^2$')\nplt.show()   ppdb.df['ATOM']['element_symbol'].value_counts().plot(kind='bar')\nplt.title('Distribution of Atom Types')\nplt.xlabel('elements')\nplt.ylabel('count')\nplt.show()",
            "title": "Plotting"
        },
        {
            "location": "/tutorials/Working_with_PDB_Structures_in_DataFrames/#computing-the-root-mean-square-deviation",
            "text": "BioPandas also comes with certain convenience functions, for example, ...  The [Root-mean-square deviation] (RMSD) is simply a measure of the average distance between atoms of 2 protein or ligand structures. This calculation of the Cartesian error follows the equation:  $$RMSD(a, b) = \\sqrt{\\frac{1}{n} \\sum^{n}_{i=1} \\big((a_{ix})^2 + (a_{iy})^2 + (a_{iz})^2 \\big)} \\\\\n= \\sqrt{\\frac{1}{n} \\sum^{n}_{i=1} || a_i + b_i||_2^2}$$  So, assuming that the we have the following 2 conformation of a ligand molecule   we can compute the RMSD as follows:  from biopandas.pdb import PandasPDB\n\nl_1 = PandasPDB().read_pdb('./data/lig_conf_1.pdb')\nl_2 = PandasPDB().read_pdb('./data/lig_conf_2.pdb')\nr = PandasPDB.rmsd(l_1.df['HETATM'], l_2.df['HETATM'], s='hydrogen', invert=True)\nprint('RMSD: %.4f Angstrom' % r)  RMSD: 2.6444 Angstrom  Note that the  s  parameter in  PandasPDB.rmsd  specifies the search string \"consider all hydrogen atoms\" and via the  invert=True  option, we say \"Compute the RMSD for everything BUT the hydrogen atoms\" or \"Compute the RSMD based on the heavy atoms only\".  Similarly, we can compute the RMSD between 2 related protein structures:   The hydrogen-free RMSD:  p_1 = PandasPDB().read_pdb('./data/1t48_995.pdb')\np_2 = PandasPDB().read_pdb('./data/1t49_995.pdb')\nr = PandasPDB.rmsd(p_1.df['ATOM'], p_2.df['ATOM'], s='hydrogen', invert=True)\nprint('RMSD: %.4f Angstrom' % r)  RMSD: 0.7377 Angstrom  Or the RMSD between the main chains only:  p_1 = PandasPDB().read_pdb('./data/1t48_995.pdb')\np_2 = PandasPDB().read_pdb('./data/1t49_995.pdb')\nr = PandasPDB.rmsd(p_1.df['ATOM'], p_2.df['ATOM'], s='main chain', invert=False)\nprint('RMSD: %.4f Angstrom' % r)  RMSD: 0.4781 Angstrom   [more to come]",
            "title": "Computing the Root Mean Square Deviation"
        },
        {
            "location": "/tutorials/Working_with_PDB_Structures_in_DataFrames/#wrapping-it-up-saving-pdb-structures",
            "text": "Finally, let's talk about how to get the PDB structures out of the DataFrame format back into the beloved .pdb format.  Let's say we loaded a PDB structure, removed it from it's hydrogens:  from biopandas.pdb import PandasPDB\nppdb = PandasPDB().read_pdb('./data/3eiy.pdb.gz')\nppdb.df['ATOM'] = ppdb.df['ATOM'][ppdb.df['ATOM']['element_symbol'] != 'H']  We can save the file using the  PandasPDB.to_pdb  method:  ppdb.to_pdb(path='./data/3eiy_stripped.pdb',\n            records=None,\n            gz=False,\n            append_newline=True)  By default, all records (that is, 'ATOM', 'HETATM', 'OTHERS', 'ANISOU') are written if we set  records=None . Alternatively, let's say we want to get rid of the 'ANISOU' entries and produce a compressed gzip archive of our PDB structure:  ppdb.to_pdb(path='./data/3eiy_stripped.pdb.gz',\n            records=['ATOM', 'HETATM', 'OTHERS'],\n            gz=True,\n            append_newline=True)",
            "title": "Wrapping it up - Saving PDB structures"
        },
        {
            "location": "/api/biopandas.pdb/",
            "text": "biopandas\n API Documentation\n\n\nTable of Contents\n\n\n\n\nbiopandas.pdb\n\n\nBioPandas module for working with Protein Data Bank (PDB)\nfiles in pandas DataFrames.\n\n\nbiopandas.pdb.PandasPDB\n\n\n\n\nPandasPDB.fetch_pdb\n\n\nPandasPDB.get\n\n\nPandasPDB.read_pdb\n\n\nPandasPDB.rmsd\n\n\nPandasPDB.to_pdb\n\n\nPandasPDB.df\n\n\n\n\n\n\n\nbiopandas.pdb.PandasPDB\n\n\nObject for working with Protein Databank structure files.\n\n\nAttributes\n\n\n\n\n\n\ndf\n (dict)\n\n\nDictionary storing pandas DataFrames for PDB record sections.\nThe dictionary keys are {'ATOM', 'HETATM', 'ANISOU', 'OTHERS'}\nwhere 'OTHERS' contains all entries that are not parsed as\n'ATOM', 'HETATM', or 'ANISOU'\n\n\n\n\n\n\npdb_text\n (str)\n\n\nPDB file contents in raw text format\n\n\n\n\n\n\nheader\n (str)\n\n\nPDB file description\n\n\n\n\n\n\ncode\n (str)\n\n\nPDB code\n\n\n\n\n\n\nMethods\n\n\nPandasPDB.fetch_pdb\n\n\nPandasPDB.fetch_pdb(pdb_code)\n\n\nFetches PDB file contents from the Protein Databank at rcsb.org.\n\n\nParameters\n\n\n\n\n\n\npdb_code\n (str)\n\n\nA 4-letter PDB code, e.g., \"3eiy\"\n\n\n\n\n\n\nReturns\n\nself\n\n\nPandasPDB.get\n\n\nPandasPDB.get(s, df=None, invert=False)\n\n\nFilter PDB DataFrames by properties\n\n\nParameters\n\n\n\n\n\n\ns\n (str  in {'main chain', 'hydrogen', 'c-alpha'})\n\n\nString to specify which entries to return\n\n\n\n\n\n\ndf\n (pandas.DataFrame, default: None)\n\n\nOptional DataFrame to perform the filter operation on.\nIf df=None, filters on self.df['ATOM']\n\n\n\n\n\n\ninvert\n (bool, default: True)\n\n\nInverts the search query. For example if s='hydrogen' and\ninvert=True, all but hydrogen entries are returned\n\n\n\n\n\n\nReturns\n\n\n\n\n\n\ndf\n (pandas.DataFrame)\n\n\nReturns a DataFrame view on the filtered entries.\n\n\n\n\n\n\nPandasPDB.read_pdb\n\n\nPandasPDB.read_pdb(path)\n\n\nRead PDB files (unzipped or gzipped) from local drive\n\n\nAttributes\n\n\n\n\n\n\npath\n (str)\n\n\nPath to the PDB file in .pdb format or gzipped format (.pdb.gz)\n\n\n\n\n\n\nReturns\n\nself\n\n\nPandasPDB.rmsd\n\n\nPandasPDB.rmsd(df1, df2, s='main chain', invert=False)\n\n\nCompute the Root Mean Square Deviation between molecules.\n\n\nParameters\n\n\n\n\n\n\ndf1\n (pandas.DataFrame)\n\n\nDataFrame with HETATM, ATOM, and/or ANISOU entries\n\n\n\n\n\n\ndf2\n (pandas.DataFrame)\n\n\nSecond DataFrame for RMSD computation against df1. Must have the\nsame number of entries as df1\n\n\n\n\n\n\ns\n (str in {'main chain', 'hydrogen', 'c-alpha'}, default: 'main chain')\n\n\nString to specify which entries to consider.\n\n\n\n\n\n\ninvert\n (bool, default: False)\n\n\nInverts the string query if true. For example, the setting\n\ns='hydrogen', invert=True\n computes the RMSD based on all\nbut hydrogen atoms.\n\n\n\n\n\n\nReturns\n\n\n\n\n\n\nrmsd\n (float)\n\n\nRoot Mean Square Deviation between df1 and df2\n\n\n\n\n\n\nPandasPDB.to_pdb\n\n\nPandasPDB.to_pdb(path, records=None, gz=False, append_newline=True)\n\n\nWrite record DataFrames to a PDB file or gzipped PDB file.\n\n\nParameters\n\n\n\n\n\n\npath\n (str)\n\n\nA valid output path for the pdb file\n\n\n\n\n\n\nrecords\n (iterable, default: None)\n\n\nA list of PDB record sections in\n{'ATOM', 'HETATM', 'ANISOU', 'OTHERS'} that are to be written.\nWrites all lines to PDB if records=None\n\n\n\n\n\n\ngz\n (bool, default: False)\n\n\nWrites a gzipped PDB file if True\n\n\n\n\n\n\nappend_newline\n (bool, default: True)\n\n\nAppends a new line at the end of the PDB file if True\n\n\n\n\n\n\nProperties\n\n\nPandasPDB.df\n\n\nAcccess dictionary of pandas DataFrames for PDB record sections.",
            "title": "Biopandas.pdb"
        },
        {
            "location": "/api/biopandas.pdb/#biopandas-api-documentation",
            "text": "Table of Contents   biopandas.pdb  BioPandas module for working with Protein Data Bank (PDB)\nfiles in pandas DataFrames.  biopandas.pdb.PandasPDB   PandasPDB.fetch_pdb  PandasPDB.get  PandasPDB.read_pdb  PandasPDB.rmsd  PandasPDB.to_pdb  PandasPDB.df",
            "title": "biopandas API Documentation"
        },
        {
            "location": "/api/biopandas.pdb/#biopandaspdbpandaspdb",
            "text": "Object for working with Protein Databank structure files.  Attributes    df  (dict)  Dictionary storing pandas DataFrames for PDB record sections.\nThe dictionary keys are {'ATOM', 'HETATM', 'ANISOU', 'OTHERS'}\nwhere 'OTHERS' contains all entries that are not parsed as\n'ATOM', 'HETATM', or 'ANISOU'    pdb_text  (str)  PDB file contents in raw text format    header  (str)  PDB file description    code  (str)  PDB code    Methods  PandasPDB.fetch_pdb  PandasPDB.fetch_pdb(pdb_code)  Fetches PDB file contents from the Protein Databank at rcsb.org.  Parameters    pdb_code  (str)  A 4-letter PDB code, e.g., \"3eiy\"    Returns \nself  PandasPDB.get  PandasPDB.get(s, df=None, invert=False)  Filter PDB DataFrames by properties  Parameters    s  (str  in {'main chain', 'hydrogen', 'c-alpha'})  String to specify which entries to return    df  (pandas.DataFrame, default: None)  Optional DataFrame to perform the filter operation on.\nIf df=None, filters on self.df['ATOM']    invert  (bool, default: True)  Inverts the search query. For example if s='hydrogen' and\ninvert=True, all but hydrogen entries are returned    Returns    df  (pandas.DataFrame)  Returns a DataFrame view on the filtered entries.    PandasPDB.read_pdb  PandasPDB.read_pdb(path)  Read PDB files (unzipped or gzipped) from local drive  Attributes    path  (str)  Path to the PDB file in .pdb format or gzipped format (.pdb.gz)    Returns \nself  PandasPDB.rmsd  PandasPDB.rmsd(df1, df2, s='main chain', invert=False)  Compute the Root Mean Square Deviation between molecules.  Parameters    df1  (pandas.DataFrame)  DataFrame with HETATM, ATOM, and/or ANISOU entries    df2  (pandas.DataFrame)  Second DataFrame for RMSD computation against df1. Must have the\nsame number of entries as df1    s  (str in {'main chain', 'hydrogen', 'c-alpha'}, default: 'main chain')  String to specify which entries to consider.    invert  (bool, default: False)  Inverts the string query if true. For example, the setting s='hydrogen', invert=True  computes the RMSD based on all\nbut hydrogen atoms.    Returns    rmsd  (float)  Root Mean Square Deviation between df1 and df2    PandasPDB.to_pdb  PandasPDB.to_pdb(path, records=None, gz=False, append_newline=True)  Write record DataFrames to a PDB file or gzipped PDB file.  Parameters    path  (str)  A valid output path for the pdb file    records  (iterable, default: None)  A list of PDB record sections in\n{'ATOM', 'HETATM', 'ANISOU', 'OTHERS'} that are to be written.\nWrites all lines to PDB if records=None    gz  (bool, default: False)  Writes a gzipped PDB file if True    append_newline  (bool, default: True)  Appends a new line at the end of the PDB file if True    Properties  PandasPDB.df  Acccess dictionary of pandas DataFrames for PDB record sections.",
            "title": "biopandas.pdb.PandasPDB"
        },
        {
            "location": "/changelog/",
            "text": "Changelog \n\n\n0.1.5.dev\n\n\n\n\nInclude test data in the PyPI package; add install_requires for pandas\n\n\n\n\n0.1.4 (2015-11-24)\n\n\n\n\nNeeded to bump the version number due to a bug in the PyPI setup.py script\n\n\nSupport for the old pandas sorting syntax (\nDataFrame.sort\n vs \nDataFrame.sort_values\n) incl. DeprecationWarning\n\n\n\n\n0.1.3 (2015-11-23)\n\n\n\n\nException handling in tests if PDB goes down (which just happened)\n\n\nAdded a separate ANISOU engine to handle those records correctly\n\n\n\n\n0.1.2 (2015-11-23)\n\n\n\n\nFirst Release",
            "title": "Changelog"
        },
        {
            "location": "/changelog/#changelog",
            "text": "0.1.5.dev   Include test data in the PyPI package; add install_requires for pandas   0.1.4 (2015-11-24)   Needed to bump the version number due to a bug in the PyPI setup.py script  Support for the old pandas sorting syntax ( DataFrame.sort  vs  DataFrame.sort_values ) incl. DeprecationWarning   0.1.3 (2015-11-23)   Exception handling in tests if PDB goes down (which just happened)  Added a separate ANISOU engine to handle those records correctly   0.1.2 (2015-11-23)   First Release",
            "title": "Changelog"
        },
        {
            "location": "/installation/",
            "text": "Installing biopandas \n\n\nYou can install \nbiopandas\n directly via pip by executing the following code from your command line:  \n\n\npip install biopandas  \n\n\n\n\n\n\nYou want to try out the latest features before they go live on PyPI? Install the \nbiopandas\n dev-version latest development version from the GitHub repository by executing\n\n\npip install git+git://github.com/rasbt/biopandas.git#egg=biopandas\n\n\n\n\n\n\nAlternatively, you download the package manually from \nPYPI\n or \nGitHub\n, unzip it, navigate into the package, and execute the command:\n\n\npython setup.py install",
            "title": "Installation"
        },
        {
            "location": "/installation/#installing-biopandas",
            "text": "You can install  biopandas  directly via pip by executing the following code from your command line:    pip install biopandas     You want to try out the latest features before they go live on PyPI? Install the  biopandas  dev-version latest development version from the GitHub repository by executing  pip install git+git://github.com/rasbt/biopandas.git#egg=biopandas   Alternatively, you download the package manually from  PYPI  or  GitHub , unzip it, navigate into the package, and execute the command:  python setup.py install",
            "title": "Installing biopandas"
        },
        {
            "location": "/contributing/",
            "text": "How to Contribute \n\n\nI would be very happy about any kind of contributions that help to improve and extend the functionality of biopandas.\n\n\nQuick Contributor Checklist\n\n\nThis is a quick checklist about the different steps of a typical contribution to biopandas and\nother open source projects. Consider copying this list to a local text file (or the issue tracker)\nand checking off items as you go.\n\n\n\n\n[ ]  Open a new \"issue\" on GitHub to discuss the new feature / bug fix  \n\n\n[ ]  Fork the biopandas repository from GitHub (if not already done earlier)\n\n\n[ ]  Create and checkout a new topic branch   \n\n\n[ ]  Implement new feature or apply the bug-fix  \n\n\n[ ]  Add appropriate unit test functions  \n\n\n[ ]  Run \nnosetests -sv\n and make sure that all unit tests pass  \n\n\n[ ]  Check/improve the test coverage by running \nnosetests --with-coverage\n\n\n[ ]  Add a note about the change to the \n./docs/sources/CHANGELOG.md\n file  \n\n\n[ ]  Modify documentation in the appropriate location under \nbiopandas/docs/sources/\n  \n\n\n[ ]  Push the topic branch to the server and create a pull request\n\n\n[ ]  Check the Travis-CI build passed at \nhttps://travis-ci.org/rasbt/biopandas\n\n\n[ ]  Check/improve the unit test coverage at \nhttps://coveralls.io/github/rasbt/biopandas\n\n\n[ ]  Check/improve the code health at \nhttps://landscape.io/github/rasbt/biopandas\n\n\n[ ]  Squash many small commits to a larger commit\n\n\n\n\n\n\nGetting Started - Creating a New Issue and Forking the Repository\n\n\n\n\nIf you don't have a \nGitHub\n account yet, please create one to contribute to this project.\n\n\nPlease submit a ticket for your issue to discuss the fix or new feature before too much time and effort is spent for the implementation.\n\n\n\n\n\n\n\n\nFork the \nbiopandas\n repository from the GitHub web interface.\n\n\n\n\n\n\n\n\nClone the \nbiopandas\n repository to your local machine\n\n\ngit clone https://github.com/<your_username>/biopandas.git\n\n\n\n\n\n\n\n\nSyncing an Existing Fork\n\n\nIf you already forked biopandas earlier, you can bring you \"Fork\" up to date\nwith the master branch as follows:\n\n\n1. Configuring a remote that points to the upstream repository on GitHub\n\n\nList the current configured remote repository for your fork by executing\n\n\n$ git remote -v\n\n\n\n\nIf you see something like\n\n\norigin  https://github.com/<your username>/biopandas.git (fetch)\norigin  https://github.com/<your username>/biopandas.git (push)\n\n\n\n\nyou need to specify a new remote \nupstream\n repository via\n\n\n$ git remote add upstream https://github.com/rasbt/biopandas.git\n\n\n\n\nNow, verify the new upstream repository you've specified for your fork by executing\n\n\n$ git remote -v\n\n\n\n\nYou should see following output if everything is configured correctly:\n\n\norigin  https://github.com/<your username>/biopandas.git (fetch)\norigin  https://github.com/<your username>/biopandas.git (push)\nupstream    https://github.com/rasbt/biopandas.git (fetch)\nupstream    https://github.com/rasbt/biopandas.git (push)\n\n\n\n\n2. Syncing your Fork\n\n\nFirst, fetch the updates of the original project's master branch by executing:\n\n\n$ git fetch upstream\n\n\n\n\nYou should see the following output\n\n\nremote: Counting objects: xx, done.\nremote: Compressing objects: 100% (xx/xx), done.\nremote: Total xx (delta xx), reused xx (delta x)\nUnpacking objects: 100% (xx/xx), done.\nFrom https://github.com/rasbt/biopandas\n * [new branch]      master     -> upstream/master\n\n\n\n\nThis means that the commits to the \nrasbt/biopandas\n master branch are now\nstored in the local branch \nupstream/master\n.\n\n\nIf you are not already on your local project's master branch, execute\n\n\n$ git checkout master\n\n\n\n\nFinally, merge the changes in upstream/master to your local master branch by\nexecuting\n\n\n$ git merge upstream/master\n\n\n\n\nwhich will give you an output that looks similar to\n\n\nUpdating xxx...xxx\nFast-forward\nSOME FILE1                    |    12 +++++++\nSOME FILE2                    |    10 +++++++\n2 files changed, 22 insertions(+),\n\n\n\n\nMaking Changes in a New Topic Branch\n\n\n1. Creating a new feature branch\n\n\nPlease avoid working directly on the master branch but create a new feature branch:\n\n\n$ git branch <new_feature>\n\n\n\n\nSwitch to the new feature branch by executing\n\n\n$ git checkout <new_feature>\n\n\n\n\n2. Developing the new feature / bug fix\n\n\n3. Testing your code\n\n\nAdding/modifying the unit tests and check if they pass:\n\n\n$ nosetests -sv\n\n\n\n\n$ nosetests --with-coverage\n\n\n\n\n4. Documenting the changes\n\n\nPlease add an entry to the \nbiopandas/docs/sources/CHANGELOG.md\n file.\nIf it is a new feature, it would also be nice if you could update the documentation in appropriate location in \nbiopandas/sources\n.\n\n\n5. Committing the changes\n\n\nWhen you are ready to commit the changes, please provide a meaningful \ncommit\n message:\n\n\n$ git add <modifies_files> # or `git add .`\n$ git commit -m '<meaningful commit message>'\n\n\n\n\n6. Optional: squashing commits\n\n\nIf you made multiple smaller commits, it would be nice if you could group them into a larger, summarizing commit. First, list your recent commit via\n\n\n$ git log\n\n\n\n\nwhich will list the commits from newest to oldest in the following format by default:\n\n\ncommit 046e3af8a9127df8eac879454f029937c8a31c41\nAuthor: rasbt <mail@sebastianraschka.com>\nDate:   Tue Nov 24 03:46:37 2015 -0500\n\n    fixed setup.py\n\ncommit c3c00f6ba0e8f48bbe1c9081b8ae3817e57ecc5c\nAuthor: rasbt <mail@sebastianraschka.com>\nDate:   Tue Nov 24 03:04:39 2015 -0500\n\n        documented feature x\n\ncommit d87934fe8726c46f0b166d6290a3bf38915d6e75\nAuthor: rasbt <mail@sebastianraschka.com>\nDate:   Tue Nov 24 02:44:45 2015 -0500\n\n        added support for feature x\n\n\n\n\nAssuming that it would make sense to group these 3 commits into one, we can execute\n\n\n$ git rebase -i HEAD~3\n\n\n\n\nwhich will bring our default git editor with the following contents:\n\n\npick d87934f added support for feature x\npick c3c00f6 documented feature x\npick 046e3af fixed setup.py\n\n\n\n\nSince \nc3c00f6\n and \n046e3af\n are related to the original commit of \nfeature x\n, let's keep the \nd87934f\n and squash the 2 following commits into this initial one by changes the lines to\n\n\npick d87934f added support for feature x\nsquash c3c00f6 documented feature x\nsquash 046e3af fixed setup.py\n\n\n\n\nNow, save the changes in your editor. Now, quitting the editor will apply the \nrebase\n changes, and the editor will open a second time, prompting you to enter a new commit message. In this case, we could enter \nsupport for feature x\n to summarize the contributions.\n\n\n7. Uploading the changes\n\n\nPush your changes to a topic branch to the git server by executing:\n\n\n$ git push origin <feature_branch>\n\n\n\n\n8. Submitting a \npull request\n\n\nGo to your GitHub repository online, select the new feature branch, and submit a new pull request:\n\n\n\n\nNotes for the Developers\n\n\nBuilding the documentation\n\n\nThe documentation is built via \nMkDocs\n; to ensure that the documentation is rendered correctly, you can view the documentation locally by executing \nmkdocs serve\n from the \nbiopandas/docs\n directory.\n\n\nFor example,\n\n\n~/github/biopandas/docs$ mkdocs serve\n\n\n\n\n1.  Editing the Tutorials\n\n\nPlease note that documents containing code examples are generated from IPython Notebook files and converted to markdown via\n\n\n~/github/mlxtend/docs/examples$ nbconvert --to markdown <file.ipynb>\n\n\n\n\nThe markdown file should be placed into the documentation directory at \nbiopandas/docs/sources\n to build the documentation via  MkDocs.\nIf you are adding a new document, please also include it in the pages section in the \nbiopandas/docs/mkdocs.yml\n file.\n\n\n2. Building the API documentation\n\n\nTo build the API documentation, navigate to \nbiopandas/docs\n and execute the \nmake_api.py\n file from this directory via\n\n\n~/github/biopandas/docs$ python make_api.py\n\n\n\n\nThis should place the API documentation into the correct directories in \nbiopandas/docs/sources/api\n.\n\n\n3. Building static HTML files of the documentation\n\n\nBuild the static HTML files of the biopandas documentation via\n\n\n~/github/biopandas/docs$ mkdocs build --clean\n\n\n\n\nTo deploy the documentation, execute\n\n\n~/github/biopandas/docs$ mkdocs gh-deploy --clean\n\n\n\n\nUploading a new version to PyPI\n\n\n1. Creating a new testing environment\n\n\nAssuming we are using \nconda\n, create a new python environment via\n\n\n$ conda create -n 'biopandas-testing' python=3 pandas\n\n\n\n\nNext, activate the environment by executing\n\n\n$ source activate biopandas-testing\n\n\n\n\n2. Installing the package from local files\n\n\nTest the installation by executing\n\n\n$ python setup.py install --record files.txt\n\n\n\n\nthe \n--record files.txt\n flag will create a \nfiles.txt\n file listing the locations where these files will be installed.\n\n\nTry to import the package to see if it works, for example, by executing\n\n\n$ python -c 'import biopandas; print(biopandas.__file__)'\n\n\n\n\nIf everything seems to be fine, remove the installation via\n\n\n$ cat files.txt | xargs rm -rf ; rm files.txt\n\n\n\n\nNext, test if \npip\n is able to install the packages. First, navigate to a different directory, and from there, install the package:\n\n\n$ pip install code/biopandas/\n\n\n\n\nand uninstall it again\n\n\n$ pip uninstall biopandas\n\n\n\n\n3. Deploying the package\n\n\nConsider deploying the package to the PyPI test server first. The setup instructions can be found \nhere\n.\n\n\n$ python setup.py sdist upload -r https://testpypi.python.org/pypi\n\n\n\n\nTest if it can be installed from there by executing\n\n\n$ pip install -i https://testpypi.python.org/pypi biopandas\n\n\n\n\nand uninstall it\n\n\n$ pip uninstall biopandas\n\n\n\n\nAfter this dry-run succeeded, repeat this process using the \"real\" PyPI:\n\n\n$ python setup.py sdist upload\n\n\n\n\n4. Removing the virtual environment\n\n\nFinally, to cleanup our local drive, remove the virtual testing environment via\n\n\n$ conda remove --name 'biopandas-testing' --all",
            "title": "Contributing"
        },
        {
            "location": "/contributing/#how-to-contribute",
            "text": "I would be very happy about any kind of contributions that help to improve and extend the functionality of biopandas.  Quick Contributor Checklist  This is a quick checklist about the different steps of a typical contribution to biopandas and\nother open source projects. Consider copying this list to a local text file (or the issue tracker)\nand checking off items as you go.   [ ]  Open a new \"issue\" on GitHub to discuss the new feature / bug fix    [ ]  Fork the biopandas repository from GitHub (if not already done earlier)  [ ]  Create and checkout a new topic branch     [ ]  Implement new feature or apply the bug-fix    [ ]  Add appropriate unit test functions    [ ]  Run  nosetests -sv  and make sure that all unit tests pass    [ ]  Check/improve the test coverage by running  nosetests --with-coverage  [ ]  Add a note about the change to the  ./docs/sources/CHANGELOG.md  file    [ ]  Modify documentation in the appropriate location under  biopandas/docs/sources/     [ ]  Push the topic branch to the server and create a pull request  [ ]  Check the Travis-CI build passed at  https://travis-ci.org/rasbt/biopandas  [ ]  Check/improve the unit test coverage at  https://coveralls.io/github/rasbt/biopandas  [ ]  Check/improve the code health at  https://landscape.io/github/rasbt/biopandas  [ ]  Squash many small commits to a larger commit",
            "title": "How to Contribute"
        },
        {
            "location": "/contributing/#getting-started-creating-a-new-issue-and-forking-the-repository",
            "text": "If you don't have a  GitHub  account yet, please create one to contribute to this project.  Please submit a ticket for your issue to discuss the fix or new feature before too much time and effort is spent for the implementation.     Fork the  biopandas  repository from the GitHub web interface.     Clone the  biopandas  repository to your local machine  git clone https://github.com/<your_username>/biopandas.git",
            "title": "Getting Started - Creating a New Issue and Forking the Repository"
        },
        {
            "location": "/contributing/#syncing-an-existing-fork",
            "text": "If you already forked biopandas earlier, you can bring you \"Fork\" up to date\nwith the master branch as follows:  1. Configuring a remote that points to the upstream repository on GitHub  List the current configured remote repository for your fork by executing  $ git remote -v  If you see something like  origin  https://github.com/<your username>/biopandas.git (fetch)\norigin  https://github.com/<your username>/biopandas.git (push)  you need to specify a new remote  upstream  repository via  $ git remote add upstream https://github.com/rasbt/biopandas.git  Now, verify the new upstream repository you've specified for your fork by executing  $ git remote -v  You should see following output if everything is configured correctly:  origin  https://github.com/<your username>/biopandas.git (fetch)\norigin  https://github.com/<your username>/biopandas.git (push)\nupstream    https://github.com/rasbt/biopandas.git (fetch)\nupstream    https://github.com/rasbt/biopandas.git (push)  2. Syncing your Fork  First, fetch the updates of the original project's master branch by executing:  $ git fetch upstream  You should see the following output  remote: Counting objects: xx, done.\nremote: Compressing objects: 100% (xx/xx), done.\nremote: Total xx (delta xx), reused xx (delta x)\nUnpacking objects: 100% (xx/xx), done.\nFrom https://github.com/rasbt/biopandas\n * [new branch]      master     -> upstream/master  This means that the commits to the  rasbt/biopandas  master branch are now\nstored in the local branch  upstream/master .  If you are not already on your local project's master branch, execute  $ git checkout master  Finally, merge the changes in upstream/master to your local master branch by\nexecuting  $ git merge upstream/master  which will give you an output that looks similar to  Updating xxx...xxx\nFast-forward\nSOME FILE1                    |    12 +++++++\nSOME FILE2                    |    10 +++++++\n2 files changed, 22 insertions(+),",
            "title": "Syncing an Existing Fork"
        },
        {
            "location": "/contributing/#making-changes-in-a-new-topic-branch",
            "text": "1. Creating a new feature branch  Please avoid working directly on the master branch but create a new feature branch:  $ git branch <new_feature>  Switch to the new feature branch by executing  $ git checkout <new_feature>  2. Developing the new feature / bug fix  3. Testing your code  Adding/modifying the unit tests and check if they pass:  $ nosetests -sv  $ nosetests --with-coverage  4. Documenting the changes  Please add an entry to the  biopandas/docs/sources/CHANGELOG.md  file.\nIf it is a new feature, it would also be nice if you could update the documentation in appropriate location in  biopandas/sources .  5. Committing the changes  When you are ready to commit the changes, please provide a meaningful  commit  message:  $ git add <modifies_files> # or `git add .`\n$ git commit -m '<meaningful commit message>'  6. Optional: squashing commits  If you made multiple smaller commits, it would be nice if you could group them into a larger, summarizing commit. First, list your recent commit via  $ git log  which will list the commits from newest to oldest in the following format by default:  commit 046e3af8a9127df8eac879454f029937c8a31c41\nAuthor: rasbt <mail@sebastianraschka.com>\nDate:   Tue Nov 24 03:46:37 2015 -0500\n\n    fixed setup.py\n\ncommit c3c00f6ba0e8f48bbe1c9081b8ae3817e57ecc5c\nAuthor: rasbt <mail@sebastianraschka.com>\nDate:   Tue Nov 24 03:04:39 2015 -0500\n\n        documented feature x\n\ncommit d87934fe8726c46f0b166d6290a3bf38915d6e75\nAuthor: rasbt <mail@sebastianraschka.com>\nDate:   Tue Nov 24 02:44:45 2015 -0500\n\n        added support for feature x  Assuming that it would make sense to group these 3 commits into one, we can execute  $ git rebase -i HEAD~3  which will bring our default git editor with the following contents:  pick d87934f added support for feature x\npick c3c00f6 documented feature x\npick 046e3af fixed setup.py  Since  c3c00f6  and  046e3af  are related to the original commit of  feature x , let's keep the  d87934f  and squash the 2 following commits into this initial one by changes the lines to  pick d87934f added support for feature x\nsquash c3c00f6 documented feature x\nsquash 046e3af fixed setup.py  Now, save the changes in your editor. Now, quitting the editor will apply the  rebase  changes, and the editor will open a second time, prompting you to enter a new commit message. In this case, we could enter  support for feature x  to summarize the contributions.  7. Uploading the changes  Push your changes to a topic branch to the git server by executing:  $ git push origin <feature_branch>  8. Submitting a  pull request  Go to your GitHub repository online, select the new feature branch, and submit a new pull request:",
            "title": "Making Changes in a New Topic Branch"
        },
        {
            "location": "/contributing/#notes-for-the-developers",
            "text": "Building the documentation  The documentation is built via  MkDocs ; to ensure that the documentation is rendered correctly, you can view the documentation locally by executing  mkdocs serve  from the  biopandas/docs  directory.  For example,  ~/github/biopandas/docs$ mkdocs serve  1.  Editing the Tutorials  Please note that documents containing code examples are generated from IPython Notebook files and converted to markdown via  ~/github/mlxtend/docs/examples$ nbconvert --to markdown <file.ipynb>  The markdown file should be placed into the documentation directory at  biopandas/docs/sources  to build the documentation via  MkDocs.\nIf you are adding a new document, please also include it in the pages section in the  biopandas/docs/mkdocs.yml  file.  2. Building the API documentation  To build the API documentation, navigate to  biopandas/docs  and execute the  make_api.py  file from this directory via  ~/github/biopandas/docs$ python make_api.py  This should place the API documentation into the correct directories in  biopandas/docs/sources/api .  3. Building static HTML files of the documentation  Build the static HTML files of the biopandas documentation via  ~/github/biopandas/docs$ mkdocs build --clean  To deploy the documentation, execute  ~/github/biopandas/docs$ mkdocs gh-deploy --clean  Uploading a new version to PyPI  1. Creating a new testing environment  Assuming we are using  conda , create a new python environment via  $ conda create -n 'biopandas-testing' python=3 pandas  Next, activate the environment by executing  $ source activate biopandas-testing  2. Installing the package from local files  Test the installation by executing  $ python setup.py install --record files.txt  the  --record files.txt  flag will create a  files.txt  file listing the locations where these files will be installed.  Try to import the package to see if it works, for example, by executing  $ python -c 'import biopandas; print(biopandas.__file__)'  If everything seems to be fine, remove the installation via  $ cat files.txt | xargs rm -rf ; rm files.txt  Next, test if  pip  is able to install the packages. First, navigate to a different directory, and from there, install the package:  $ pip install code/biopandas/  and uninstall it again  $ pip uninstall biopandas  3. Deploying the package  Consider deploying the package to the PyPI test server first. The setup instructions can be found  here .  $ python setup.py sdist upload -r https://testpypi.python.org/pypi  Test if it can be installed from there by executing  $ pip install -i https://testpypi.python.org/pypi biopandas  and uninstall it  $ pip uninstall biopandas  After this dry-run succeeded, repeat this process using the \"real\" PyPI:  $ python setup.py sdist upload  4. Removing the virtual environment  Finally, to cleanup our local drive, remove the virtual testing environment via  $ conda remove --name 'biopandas-testing' --all",
            "title": "Notes for the Developers"
        }
    ]
}